---
output: rmarkdown::github_document
---
```{r include=FALSE}
knitr::opts_chunk$set(message=FALSE, warning=FALSE, collapse=TRUE)
```
# htmlunit

Tools to Scrape Dynamic Web Content via the 'HtmlUnit' Java Library

## Description

`HtmlUnit` (<http://htmlunit.sourceforge.net/>) is _a "'GUI'-Less 
browser for 'Java' programs". It models 'HTML' documents and provides an 'API' 
that allows one to invoke pages, fill out forms, click links and more just like 
one does in a "normal" browser. The library has fairly good and constantly
improving 'JavaScript' support and is able to work even with quite complex 'AJAX' 
libraries, simulating 'Chrome', 'Firefox' or 'Internet Explorer' depending on
the configuration used. It is typically used for testing purposes or to retrieve 
information from web sites._

Tools are provided to work with this library at a higher level than provided by
the exposed 'Java' libraries in the [`htmlunitjars`](https://gitlab.com/hrbrmstr/htmlunitjars)
package.

## What's Inside The Tin

The following functions are implemented:

### Standard

- `hu_read_html`:	Read HTML from a URL with Browser Emulation & in a JavaScript Context

### DSL

- `web_client`:	Create a new HtmlUnit WebClient instance

- `wc_browser_info`:	Retreive information about the browser used to create the 'webclient'
- `wc_content_length`:	Return content length of the last web request for current page
- `wc_content_type`:	Return content type of web request for current page
- `wc_css`:	Enable/Disable CSS support
- `wc_dnt`:	Enable/Disable Do-Not-Track
- `wc_geo`:	Enable/Disable Geolocation
- `wc_go`:	Visit a URL
- `wc_headers`:	Return response headers of the last web request for current page
- `wc_img_dl`:	Enable/Disable Image Downloading
- `wc_load_time`:	Return load time of the last web request for current page
- `wc_render`:	Retrieve current page contents
- `wc_resize`:	Resize the virtual browser window
- `wc_status`:	Return status code of web request for current page
- `wc_timeout`:	Change default request timeout
- `wc_title`:	Return page title for current page
- `wc_url`:	Return load time of the last web request for current page
- `wc_use_insecure_ssl`:	Enable/Disable Ignoring SSL Validation Issues
- `wc_wait`:	Block HtlUnit final rendering blocks until all background JavaScript tasks have finished executing

## Installation

```{r eval=FALSE}
devtools::install_github("hrbrmstr/htmlunitjars")
devtools::install_github("hrbrmstr/htmlunit")
```

```{r message=FALSE, warning=FALSE, error=FALSE, include=FALSE}
options(width=120)
```

## Usage

```{r message=FALSE, warning=FALSE, error=FALSE}
library(htmlunit)

# current verison
packageVersion("htmlunit")

```

Something `xml2::read_html()` cannot do, read the table from <https://hrbrmstr.github.io/htmlunitjars/index.html>:

![](man/figures/test-url-table.png)

```{r}
test_url <- "https://hrbrmstr.github.io/htmlunitjars/index.html"

pg <- xml2::read_html(test_url)

html_table(pg)
```

☹️

But, `hu_read_html()` can!

```{r}
pg <- hu_read_html(test_url)

html_table(pg)
```

All without needing a separate Selenium or Splash server instance.

### DSL

```{r}
wc <- web_client()

wc %>% wc_browser_info()

wc %>% wc_go(test_url)

wc %>% wc_render("html") 

wc %>% wc_render("parsed") 

wc %>% wc_render("text") 
```